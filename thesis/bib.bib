@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={1998},
  publisher={MIT press}
}

@ARTICLE{6145622,
author={C. B. {Browne} and E. {Powley} and D. {Whitehouse} and S. M. {Lucas} and P. I. {Cowling} and P. {Rohlfshagen} and S. {Tavener} and D. {Perez} and S. {Samothrakis} and S. {Colton}},
journal={IEEE Transactions on Computational Intelligence and AI in Games},
title={A Survey of Monte Carlo Tree Search Methods},
year={2012},
volume={4},
number={1},
pages={1-43},
keywords={game theory;Monte Carlo methods;tree searching;Monte carlo tree search methods;random sampling generality;computer Go;MCTS research;key game;nongame domains;Games;Monte Carlo methods;Artificial intelligence;Game theory;Computers;Markov processes;Decision theory;Artificial intelligence (AI);bandit-based methods;computer Go;game search;Monte Carlo tree search (MCTS);upper confidence bounds (UCB);upper confidence bounds for trees (UCT)},
doi={10.1109/TCIAIG.2012.2186810},
ISSN={1943-068X},
month={March},}

@phdthesis{de2016monte,
  title={Monte Carlo Tree Search with Options for General Video Game Playing},
  author={de Waard, Maarten},
  year={2016},
  month={February},
  school={University of Amsterdam}
  }
  
@InProceedings{pmlr-v97-harutyunyan19a,
  title = 	 {Per-Decision Option Discounting},
  author = 	 {Harutyunyan, Anna and Vrancx, Peter and Hamel, Philippe and Nowe, Ann and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2644--2652},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/harutyunyan19a/harutyunyan19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/harutyunyan19a.html},
  abstract = 	 {In order to solve complex problems an agent must be able to reason over a sufficiently long horizon. Temporal abstraction, commonly modeled through options, offers the ability to reason at many timescales, but the horizon length is still determined by the discount factor of the underlying Markov Decision Process. We propose a modification to the options framework that naturally scales the agent’s horizon with option length. We show that the proposed option-step discount controls a bias-variance trade-off, with larger discounts (counter-intuitively) leading to less estimation variance.}
}

@article{DBLP:journals/corr/abs-1802-10363,
  author    = {Diego P{\'{e}}rez{-}Li{\'{e}}bana and
               Jialin Liu and
               Ahmed Khalifa and
               Raluca D. Gaina and
               Julian Togelius and
               Simon M. Lucas},
  title     = {General Video Game {AI:} a Multi-Track Framework for Evaluating Agents,
               Games and Content Generation Algorithms},
  journal   = {CoRR},
  volume    = {abs/1802.10363},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.10363},
  archivePrefix = {arXiv},
  eprint    = {1802.10363},
  timestamp = {Wed, 29 Aug 2018 17:16:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1802-10363},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{7317937,
author={F. {Frydenberg} and K. R. {Andersen} and S. {Risi} and J. {Togelius}},
booktitle={2015 IEEE Conference on Computational Intelligence and Games (CIG)},
title={Investigating MCTS modifications in general video game playing},
year={2015},
volume={},
number={},
pages={107-113},
keywords={artificial intelligence;computer games;Monte Carlo methods;tree searching;Monte Carlo tree search;board games;MCTS algorithm;general video game playing;general video game AI;UCT reverse penalty;vanilla MCTS controller;GVG-AI framework;Games;Avatars;Artificial intelligence;Monte Carlo methods;Animals;Sprites (computer);Missiles},
doi={10.1109/CIG.2015.7317937},
ISSN={2325-4289},
month={Aug},}

@INPROCEEDINGS{7860448,
author={D. J. N. J. {Soemers} and C. F. {Sironi} and T. {Schuster} and M. H. M. {Winands}},
booktitle={2016 IEEE Conference on Computational Intelligence and Games (CIG)},
title={Enhancements for real-time Monte-Carlo Tree Search in General Video Game Playing},
year={2016},
volume={},
number={},
pages={1-8},
keywords={computer games;Monte Carlo methods;real-time systems;software agents;tree searching;real-time Monte-Carlo tree search;general video game playing;GVGP;artificial intelligence;real-time video games;MCTS;progressive history;n-gram selection;tree reuse;breadth-first tree initialization;loss avoidance;novelty-based pruning;knowledge-based evaluations;deterministic game detection;agents;Games;Monte Carlo methods;History;Real-time systems;Silicon;Knowledge based systems;Avatars},
doi={10.1109/CIG.2016.7860448},
ISSN={2325-4289},
month={Sep.},}

@inproceedings{wang2012multi,
  title={Multi-objective monte-carlo tree search},
  author={Wang, Weijia and Sebag, Michele},
  booktitle={Asian conference on machine learning},
  volume={25},
  pages={507--522},
  year={2012}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{Kocsis-Szepesv:2006,
 author = {Kocsis, Levente and Szepesv\'{a}ri, Csaba},
 title = {Bandit Based Monte-carlo Planning},
 booktitle = {Proceedings of the 17th European Conference on Machine Learning},
 series = {ECML'06},
 year = {2006},
 isbn = {3-540-45375-X, 978-3-540-45375-8},
 location = {Berlin, Germany},
 pages = {282--293},
 numpages = {12},
 url = {http://dx.doi.org/10.1007/11871842_29},
 doi = {10.1007/11871842_29},
 acmid = {2091633},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@INPROCEEDINGS{Coulom06mcts,
    author = {Rémi Coulom},
    title = {Efficient selectivity and backup operators in Monte-Carlo tree search},
    booktitle = {In: Proceedings Computers and Games 2006},
    year = {2006},
    publisher = {Springer-Verlag}
}

@article{Silver_2016,
  added-at = {2016-03-11T14:36:05.000+0100},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/ytyoun},
  doi = {10.1038/nature16961},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  journal = {Nature},
  keywords = {baduk go google},
  month = jan,
  number = 7587,
  pages = {484--489},
  publisher = {Nature Publishing Group},
  timestamp = {2016-03-11T14:37:40.000+0100},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  volume = 529,
  year = 2016
}

@article{Campbell:2002:DB:512148.512152,
 author = {Campbell, Murray and Hoane,Jr., A. Joseph and Hsu, Feng-hsiung},
 title = {Deep Blue},
 journal = {Artif. Intell.},
 issue_date = {January 2002},
 volume = {134},
 number = {1-2},
 month = jan,
 year = {2002},
 issn = {0004-3702},
 pages = {57--83},
 numpages = {27},
 url = {http://dx.doi.org/10.1016/S0004-3702(01)00129-1},
 doi = {10.1016/S0004-3702(01)00129-1},
 acmid = {512152},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
 keywords = {computer chess, evaluation function, game tree search, parallel search, search extensions, selective search},
}

@INPROCEEDINGS{6633610,
author={T. {Schaul}},
booktitle={2013 IEEE Conference on Computational Inteligence in Games (CIG)},
title={A video game description language for model-based or interactive learning},
year={2013},
volume={},
number={},
pages={1-8},
keywords={computer games;learning (artificial intelligence);multi-agent systems;ontologies (artificial intelligence);planning (artificial intelligence);program control structures;search problems;software libraries;evolutionary search;reinforcement learning algorithm;game dynamics;library usefulness;visual observations;abstract observations;learning agents;planning algorithms;benchmark problems;control structures;ontology;streamlined language design;software library;2D video games;high-level description language;PyVGDL;computational games;computational intelligence;interactive learning;video game description language;Games;Ontologies;Avatars;Libraries;Syntactics;Benchmark testing;Visualization},
doi={10.1109/CIG.2013.6633610},
ISSN={2325-4289},
month={Aug},}


@misc{MCTS-total-war,
  author = {Alex J. Champandard},
  title = {{Monte-Carlo Tree Search in TOTAL WAR: ROME II’s Campaign AI}},
  howpublished = "\url{http://aigamedev.com/open/coverage/mcts-rome-ii/}",
  year = {2014}, 
  note = "[Online; accessed 10-April-2019]"
}